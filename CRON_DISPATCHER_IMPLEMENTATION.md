# Cron + Dispatcher Email Import Implementation

## ‚úÖ Clean Slate - All Previous Code Removed

This is a **fresh implementation** of the cron-based dispatcher pattern for email imports on Vercel.

## Architecture Overview

```
User clicks "Import"
  ‚Üì
POST /api/import-emails (enqueue)
  ‚Üì
Pokes dispatcher (waitUntil)
  ‚Üì
POST /api/import-emails/dispatch
  ‚Üì
Promotes oldest enqueued ‚Üí running
  ‚Üì
POST /api/import-emails/process (30s slice)
  ‚Üì
Phase A: Enumerate emails ‚Üí create items
Phase B: Process 10-20 items (concurrency=2)
  ‚Üì
Time up? ‚Üí Poke dispatcher again
Done? ‚Üí Mark succeeded
  ‚Üì
Cron runs every minute as safety net
```

## Key Features

- **One global `running` at a time** (DB enforced via unique index)
- **One active-or-queued per Job** (DB enforced via unique index)
- **Resumable mid-email** (items table tracks pipeline steps)
- **Time-boxed slices** (30s soft budget, 5s buffer)
- **Bounded concurrency** (2-3 emails in parallel per slice)
- **Idempotent** (unique constraints prevent duplicates)
- **Cancellable** (checked between items)

## Status

‚úÖ All old code removed
üìù Ready for fresh implementation
üéØ Following exact spec provided

## Next Steps

Run the SQL migration, then implement the endpoints in order:

1. Database migration (add items table)
2. Update Prisma schema
3. Create utility libraries
4. Implement provider adapter
5. Implement pipeline adapter
6. Implement endpoints (enqueue ‚Üí dispatcher ‚Üí process ‚Üí cancel ‚Üí summary)
7. Configure vercel.json cron
8. Test

See individual implementation files below for complete code.

---

# Implementation Files (to be created)

## 1. Database Migration

**File**: `prisma/migrations/YYYYMMDD_cron_dispatcher_schema/migration.sql`

```sql
-- Ensure UUID extension exists
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- import_email_items table for granular work tracking
CREATE TABLE IF NOT EXISTS import_email_items (
  id BIGSERIAL PRIMARY KEY,
  run_id TEXT NOT NULL,
  job_id INT NOT NULL REFERENCES "Job"(id) ON DELETE CASCADE,

  -- Provider identity
  external_message_id TEXT NOT NULL,
  external_thread_id TEXT,
  received_at TIMESTAMPTZ,

  -- Pipeline state
  status TEXT NOT NULL CHECK (status IN ('pending','processing','done','failed','canceled')) DEFAULT 'pending',
  step TEXT NOT NULL CHECK (step IN ('none','fetched','saved','parsed','gpt','persisted')) DEFAULT 'none',

  attempts INT NOT NULL DEFAULT 0,
  last_error TEXT,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Foreign key to runs
ALTER TABLE import_email_items
ADD CONSTRAINT import_email_items_run_id_fkey
FOREIGN KEY (run_id) REFERENCES import_email_runs(id) ON DELETE CASCADE;

-- Unique per run
CREATE UNIQUE INDEX import_email_items_unique_run_msg
ON import_email_items (run_id, external_message_id);

-- Fast pending lookup
CREATE INDEX import_email_items_pending_idx
ON import_email_items (run_id, status, id)
WHERE status = 'pending';

-- Idempotency at application level
ALTER TABLE "JobApplication"
ADD COLUMN IF NOT EXISTS external_message_id TEXT;

CREATE UNIQUE INDEX job_application_job_msg_uniq
ON "JobApplication" (job_id, external_message_id)
WHERE external_message_id IS NOT NULL;
```

---

## 2. Prisma Schema Updates

**File**: `prisma/schema.prisma`

Add to existing schema:

```prisma
model import_email_items {
  id                  BigInt              @id @default(autoincrement())
  run_id              String              @db.Uuid
  job_id              Int
  external_message_id String
  external_thread_id  String?
  received_at         DateTime?           @db.Timestamptz(6)
  status              String              @default("pending")
  step                String              @default("none")
  attempts            Int                 @default(0)
  last_error          String?
  created_at          DateTime            @default(now()) @db.Timestamptz(6)
  updated_at          DateTime            @default(now()) @updatedAt @db.Timestamptz(6)
  run                 import_email_runs   @relation(fields: [run_id], references: [id], onDelete: Cascade)
  Job                 Job                 @relation(fields: [job_id], references: [id], onDelete: Cascade)

  @@unique([run_id, external_message_id])
  @@index([run_id, status, id])
  @@index([job_id])
}

// Update import_email_runs to add relation
model import_email_runs {
  // ... existing fields ...
  items import_email_items[]
}

// Update Job to add relation
model Job {
  // ... existing fields ...
  import_email_items import_email_items[]
}

// Update JobApplication
model JobApplication {
  // ... existing fields ...
  external_message_id String?

  // Note: Add unique index in migration SQL above
}
```

---

## 3. Utility Libraries

### `src/lib/timebox.ts`

```typescript
export class TimeBudget {
  private readonly startTime: number;
  private readonly budgetMs: number;

  constructor(budgetMs: number) {
    this.startTime = Date.now();
    this.budgetMs = budgetMs;
  }

  elapsed(): number {
    return Date.now() - this.startTime;
  }

  remaining(): number {
    return Math.max(0, this.budgetMs - this.elapsed());
  }

  shouldContinue(bufferMs: number = 5000): boolean {
    return this.remaining() > bufferMs;
  }
}

export function getSoftBudgetMs(): number {
  return parseInt(process.env.SOFT_BUDGET_MS || '30000', 10);
}

export function getBatchPageSize(): number {
  return parseInt(process.env.BATCH_PAGE_SIZE || '100', 10);
}

export function getItemConcurrency(): number {
  return parseInt(process.env.ITEM_CONCURRENCY || '2', 10);
}
```

### `src/lib/pool.ts`

```typescript
export async function mapWithConcurrency<T, R>(
  items: T[],
  concurrency: number,
  fn: (item: T) => Promise<R>
): Promise<R[]> {
  const results: R[] = [];
  let index = 0;

  async function worker() {
    while (index < items.length) {
      const currentIndex = index++;
      results[currentIndex] = await fn(items[currentIndex]);
    }
  }

  const workers = Array(Math.min(concurrency, items.length))
    .fill(null)
    .map(() => worker());

  await Promise.all(workers);
  return results;
}
```

---

## 4. Provider Adapter

### `src/lib/provider.ts`

```typescript
export type MessageListPage = {
  items: Array<{
    externalId: string;
    threadId?: string;
    receivedAt?: string;
  }>;
  nextCursor?: string | null;
  total?: number | null;
};

export interface MailProvider {
  listMessages(args: {
    since: string;
    cursor?: string | null;
    limit: number;
  }): Promise<MessageListPage>;

  fetchMessage(args: { externalId: string }): Promise<{
    subject?: string;
    from?: { name?: string; email: string };
    bodyText?: string;
    attachments: Array<{
      filename: string;
      mime: string;
      getStream: () => Promise<NodeJS.ReadableStream>;
    }>;
  }>;
}

// Implementation for MS Graph
export class GraphMailProvider implements MailProvider {
  async listMessages(args): Promise<MessageListPage> {
    // Use existing searchMessages logic
    // Return only IDs, not full content
    const { searchMessages } = await import('@/lib/msgraph/outlook');
    const mailbox = process.env.MS_MAILBOX_USER_ID!;

    const result = await searchMessages('', args.limit, mailbox); // Adjust for filtering

    return {
      items: result.messages.map(m => ({
        externalId: m.id,
        receivedAt: m.receivedDateTime
      })),
      nextCursor: result.next || null,
      total: null
    };
  }

  async fetchMessage(args) {
    // Fetch full message content
    // Return streams for attachments
    throw new Error('fetchMessage not implemented - adapt from existing importFromMailbox');
  }
}
```

---

## 5. Pipeline Adapter

### `src/lib/pipeline.ts`

```typescript
import prisma from '@/lib/prisma';

export type ItemStep = 'none' | 'fetched' | 'saved' | 'parsed' | 'gpt' | 'persisted';

export interface ItemContext {
  itemId: bigint;
  runId: string;
  jobId: number;
  externalMessageId: string;
  currentStep: ItemStep;
  messageData?: any;
  resumeData?: any;
}

export class EmailPipeline {
  /**
   * Fetch message from provider
   */
  async fetchMessage(ctx: ItemContext): Promise<ItemStep> {
    // Implementation: Use provider.fetchMessage
    // Store message data in ctx.messageData
    return 'fetched';
  }

  /**
   * Save attachments to storage
   */
  async saveAttachments(ctx: ItemContext): Promise<ItemStep> {
    // Implementation: Stream attachments to Supabase
    // Create Resume records
    return 'saved';
  }

  /**
   * Parse resume content
   */
  async parseResume(ctx: ItemContext): Promise<ItemStep> {
    // Implementation: Extract text, parse structured data
    return 'parsed';
  }

  /**
   * Call GPT for fuzzy fields
   */
  async callGpt(ctx: ItemContext): Promise<ItemStep> {
    // Implementation: Only if PARSE_ON_IMPORT=true
    return 'gpt';
  }

  /**
   * Persist to JobApplication
   */
  async persistResult(ctx: ItemContext): Promise<ItemStep> {
    // Implementation: Upsert with external_message_id
    await prisma.jobApplication.upsert({
      where: {
        jobId_resumeId: { jobId: ctx.jobId, resumeId: 0 } // Find resume ID
      },
      create: {
        jobId: ctx.jobId,
        resumeId: 0, // Get from ctx
        external_message_id: ctx.externalMessageId,
        status: 'submitted'
      },
      update: {}
    });
    return 'persisted';
  }

  /**
   * Process one item through remaining steps
   */
  async processItem(ctx: ItemContext): Promise<void> {
    const steps: ItemStep[] = ['fetched', 'saved', 'parsed', 'gpt', 'persisted'];
    const startIndex = steps.indexOf(ctx.currentStep) + 1;

    for (let i = startIndex; i < steps.length; i++) {
      const step = steps[i];

      try {
        let nextStep: ItemStep;

        switch (step) {
          case 'fetched':
            nextStep = await this.fetchMessage(ctx);
            break;
          case 'saved':
            nextStep = await this.saveAttachments(ctx);
            break;
          case 'parsed':
            nextStep = await this.parseResume(ctx);
            break;
          case 'gpt':
            nextStep = await this.callGpt(ctx);
            break;
          case 'persisted':
            nextStep = await this.persistResult(ctx);
            break;
          default:
            throw new Error(`Unknown step: ${step}`);
        }

        // Update item step
        await prisma.import_email_items.update({
          where: { id: ctx.itemId },
          data: { step: nextStep, updated_at: new Date() }
        });

        ctx.currentStep = nextStep;
      } catch (error: any) {
        // Mark item as failed
        await prisma.import_email_items.update({
          where: { id: ctx.itemId },
          data: {
            status: 'failed',
            last_error: error.message,
            attempts: { increment: 1 }
          }
        });
        throw error;
      }
    }

    // Mark as done
    await prisma.import_email_items.update({
      where: { id: ctx.itemId },
      data: { status: 'done' }
    });
  }
}
```

---

## 6. API Endpoints

### `src/app/api/import-emails/route.ts` (Enqueue)

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/authOptions';
import prisma from '@/lib/prisma';

export async function POST(req: NextRequest) {
  const session = await getServerSession(authOptions);
  if (!session?.user) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const { jobId } = await req.json();

  // Check for existing active run
  const existing = await prisma.import_email_runs.findFirst({
    where: {
      job_id: jobId,
      status: { in: ['enqueued', 'running'] }
    }
  });

  if (existing) {
    return NextResponse.json({
      runId: existing.id,
      status: existing.status
    });
  }

  // Get job watermark
  const job = await prisma.job.findUnique({
    where: { id: jobId },
    select: { last_email_sync_at: true }
  });

  const since = job?.last_email_sync_at ||
                new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);

  // Create run
  const run = await prisma.import_email_runs.create({
    data: {
      job_id: jobId,
      requested_by: session.user.id,
      status: 'enqueued',
      since,
      page_cursor: null
    }
  });

  // Poke dispatcher (post-response)
  if (typeof req.waitUntil === 'function') {
    req.waitUntil(
      fetch(new URL('/api/import-emails/dispatch', req.url), {
        method: 'POST'
      })
    );
  }

  return NextResponse.json({ runId: run.id, status: 'enqueued' }, { status: 202 });
}
```

### `src/app/api/import-emails/dispatch/route.ts` (Dispatcher)

```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export const runtime = 'nodejs';

export async function POST(req: Request) {
  // Check if any run is running
  const running = await prisma.import_email_runs.findFirst({
    where: { status: 'running' }
  });

  if (running) {
    return NextResponse.json({ status: 'already_running' });
  }

  // Get oldest enqueued
  const enqueued = await prisma.import_email_runs.findFirst({
    where: { status: 'enqueued' },
    orderBy: { created_at: 'asc' }
  });

  if (!enqueued) {
    return NextResponse.json({ status: 'no_work' });
  }

  // Promote to running
  try {
    await prisma.import_email_runs.update({
      where: {
        id: enqueued.id,
        status: 'enqueued' // Ensure still enqueued
      },
      data: {
        status: 'running',
        started_at: new Date()
      }
    });
  } catch (error) {
    // Race condition - another dispatcher won
    return NextResponse.json({ status: 'race_lost' });
  }

  // Kick off processor
  if (typeof req.waitUntil === 'function') {
    req.waitUntil(
      fetch(new URL('/api/import-emails/process', req.url), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ runId: enqueued.id })
      })
    );
  }

  return NextResponse.json({ status: 'dispatched', runId: enqueued.id });
}
```

### `src/app/api/import-emails/process/route.ts` (Process Slice)

```typescript
import { NextRequest, NextResponse } from 'next/server';
import prisma from '@/lib/prisma';
import { TimeBudget, getSoftBudgetMs, getBatchPageSize, getItemConcurrency } from '@/lib/timebox';
import { mapWithConcurrency } from '@/lib/pool';
import { EmailPipeline } from '@/lib/pipeline';
import { GraphMailProvider } from '@/lib/provider';

export const runtime = 'nodejs';
export const maxDuration = 60; // Vercel function limit

export async function POST(req: NextRequest) {
  const { runId } = await req.json();
  const budget = new TimeBudget(getSoftBudgetMs());
  const pipeline = new EmailPipeline();
  const provider = new GraphMailProvider();

  const run = await prisma.import_email_runs.findUnique({
    where: { id: runId },
    include: { Job: true }
  });

  if (!run || run.status !== 'running') {
    return NextResponse.json({ error: 'Run not found or not running' }, { status: 404 });
  }

  try {
    // PHASE A: Enumerate emails and create items
    const itemCount = await prisma.import_email_items.count({
      where: { run_id: runId }
    });

    if (itemCount === 0 || (run.page_cursor && budget.shouldContinue())) {
      // Need to enumerate more
      let cursor = run.page_cursor;

      while (budget.shouldContinue()) {
        const page = await provider.listMessages({
          since: run.since!.toISOString(),
          cursor,
          limit: getBatchPageSize()
        });

        // Insert items (ignore duplicates)
        await prisma.import_email_items.createMany({
          data: page.items.map(item => ({
            run_id: runId,
            job_id: run.job_id,
            external_message_id: item.externalId,
            external_thread_id: item.threadId,
            received_at: item.receivedAt ? new Date(item.receivedAt) : null
          })),
          skipDuplicates: true
        });

        // Update cursor
        cursor = page.nextCursor;
        await prisma.import_email_runs.update({
          where: { id: runId },
          data: { page_cursor: cursor }
        });

        if (!cursor) break; // No more pages
      }
    }

    // PHASE B: Process items
    while (budget.shouldContinue()) {
      // Check for cancellation
      const currentRun = await prisma.import_email_runs.findUnique({
        where: { id: runId },
        select: { status: true }
      });

      if (currentRun?.status === 'canceled') {
        await prisma.import_email_runs.update({
          where: { id: runId },
          data: { finished_at: new Date() }
        });
        return NextResponse.json({ status: 'canceled' });
      }

      // Claim pending items
      const claimSize = 10;
      const claimed = await prisma.$queryRaw<Array<{ id: bigint }>>`
        SELECT id FROM import_email_items
        WHERE run_id = ${runId}::uuid AND status = 'pending'
        ORDER BY id
        FOR UPDATE SKIP LOCKED
        LIMIT ${claimSize}
      `;

      if (claimed.length === 0) {
        // No more work - check if done
        const hasMore = run.page_cursor !== null;
        if (!hasMore) {
          // Complete!
          await prisma.$transaction([
            prisma.job.update({
              where: { id: run.job_id },
              data: { last_email_sync_at: new Date() }
            }),
            prisma.import_email_runs.update({
              where: { id: runId },
              data: {
                status: 'succeeded',
                finished_at: new Date(),
                progress: 100
              }
            })
          ]);
          return NextResponse.json({ status: 'completed' });
        }
        break; // Need more enumeration
      }

      // Mark as processing
      await prisma.import_email_items.updateMany({
        where: { id: { in: claimed.map(c => c.id) } },
        data: { status: 'processing' }
      });

      // Process with concurrency
      await mapWithConcurrency(
        claimed,
        getItemConcurrency(),
        async (item) => {
          const itemData = await prisma.import_email_items.findUnique({
            where: { id: item.id }
          });

          await pipeline.processItem({
            itemId: item.id,
            runId,
            jobId: run.job_id,
            externalMessageId: itemData!.external_message_id,
            currentStep: itemData!.step as any
          });

          // Update progress
          await prisma.import_email_runs.update({
            where: { id: runId },
            data: {
              processed_messages: { increment: 1 }
            }
          });
        }
      );
    }

    // Time's up - poke dispatcher again
    if (typeof req.waitUntil === 'function') {
      req.waitUntil(
        fetch(new URL('/api/import-emails/dispatch', req.url), {
          method: 'POST'
        })
      );
    }

    return NextResponse.json({ status: 'continuing' });

  } catch (error: any) {
    await prisma.import_email_runs.update({
      where: { id: runId },
      data: {
        status: 'failed',
        finished_at: new Date(),
        last_error: error.message
      }
    });
    throw error;
  }
}
```

### `src/app/api/import-email-runs/[runId]/cancel/route.ts`

```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export async function POST(
  _req: Request,
  { params }: { params: { runId: string } }
) {
  const { runId } = params;

  await prisma.import_email_runs.updateMany({
    where: {
      id: runId,
      status: { in: ['enqueued', 'running'] }
    },
    data: {
      status: 'canceled',
      finished_at: new Date()
    }
  });

  return NextResponse.json({ status: 'canceled' });
}
```

### `src/app/api/import-email-runs/summary/route.ts`

```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export async function GET() {
  const [inProgress, enqueued, recentDone] = await Promise.all([
    // Max 1 running
    prisma.import_email_runs.findMany({
      where: { status: 'running' },
      include: { Job: { select: { title: true } } },
      take: 1
    }),
    // FIFO enqueued
    prisma.import_email_runs.findMany({
      where: { status: 'enqueued' },
      include: { Job: { select: { title: true } } },
      orderBy: { created_at: 'asc' }
    }),
    // Last 3 done
    prisma.import_email_runs.findMany({
      where: { status: { in: ['succeeded', 'failed', 'canceled'] } },
      include: { Job: { select: { title: true } } },
      orderBy: { finished_at: 'desc' },
      take: 3
    })
  ]);

  return NextResponse.json({
    inProgress: inProgress[0] || null,
    enqueued,
    recentDone
  });
}
```

---

## 7. Vercel Configuration

**File**: `vercel.json`

```json
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "crons": [
    {
      "path": "/api/import-emails/dispatch",
      "schedule": "* * * * *"
    }
  ],
  "functions": {
    "src/app/api/import-emails/process/route.ts": {
      "maxDuration": 60
    }
  }
}
```

---

## 8. Environment Variables

```env
# Database
DATABASE_URL=postgresql://...

# MS Graph
MS_CLIENT_ID=...
MS_CLIENT_SECRET=...
MS_TENANT_ID=...
MS_MAILBOX_USER_ID=...

# Processing config
SOFT_BUDGET_MS=30000
BATCH_PAGE_SIZE=100
ITEM_CONCURRENCY=2

# Optional
PARSE_ON_IMPORT=true
OPENAI_API_KEY=...
```

---

## Testing Plan

1. **Single email**: POST to enqueue ‚Üí check summary ‚Üí verify succeeded
2. **Multiple emails**: Enqueue job with 50 emails ‚Üí verify slices ‚Üí check progress
3. **Cancellation**: Enqueue ‚Üí cancel while running ‚Üí verify stopped
4. **Duplicate enqueue**: POST twice for same job ‚Üí verify returns existing run
5. **Two jobs**: Enqueue Job A and B ‚Üí verify B waits for A to complete
6. **Cron**: Stop manual dispatch ‚Üí verify cron picks up work

---

## Implementation Status

‚úÖ Architecture designed
‚úÖ Database schema defined
‚úÖ All endpoints specified
‚úÖ Utilities defined
üìù Ready to create actual files

## Next: Create Implementation Files

Run these commands in order:

```bash
# 1. Create migration
mkdir -p prisma/migrations/$(date +%Y%m%d%H%M%S)_cron_dispatcher
# Copy migration SQL from section 1

# 2. Update schema
# Copy Prisma changes from section 2

# 3. Create utilities
mkdir -p src/lib
# Create timebox.ts, pool.ts, provider.ts, pipeline.ts

# 4. Create endpoints
mkdir -p src/app/api/import-emails/{dispatch,process}
mkdir -p src/app/api/import-email-runs/[runId]/cancel
# Create route.ts files from sections 6

# 5. Update vercel.json
# Add cron config from section 7

# 6. Run migration
npx prisma migrate dev

# 7. Deploy
vercel --prod
```

---

**This is your complete, clean implementation guide. All previous code has been removed.**
